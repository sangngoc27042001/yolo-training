{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b8629e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.248 ðŸš€ Python-3.12.10 torch-2.9.1 CPU (Apple M4 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/phone_detection2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxslim>=0.1.71 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (0.1.82)\n",
      "Requirement already satisfied: onnxruntime in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (1.23.2)\n",
      "Requirement already satisfied: colorama in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.6)\n",
      "Requirement already satisfied: ml-dtypes in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.1)\n",
      "Requirement already satisfied: onnx in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.19.0)\n",
      "Requirement already satisfied: packaging in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Requirement already satisfied: sympy>=1.13.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (25.12.19)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (2.0.2)\n",
      "Requirement already satisfied: protobuf in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from sympy>=1.13.1->onnxslim>=0.1.71) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnx->onnxslim>=0.1.71) (4.15.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.7s\n",
      "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: onnxslim>=0.1.71 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (0.1.82)\n",
      "Requirement already satisfied: onnxruntime in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (1.23.2)\n",
      "Requirement already satisfied: colorama in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.6)\n",
      "Requirement already satisfied: ml-dtypes in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.1)\n",
      "Requirement already satisfied: onnx in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.19.0)\n",
      "Requirement already satisfied: packaging in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Requirement already satisfied: sympy>=1.13.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (25.12.19)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (2.0.2)\n",
      "Requirement already satisfied: protobuf in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from sympy>=1.13.1->onnxslim>=0.1.71) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnx->onnxslim>=0.1.71) (4.15.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.3s\n",
      "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 22...\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.7s, saved as 'runs/detect/phone_detection2/weights/best.onnx' (10.2 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "ERROR âŒ \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure 3.3s: in user code:\n",
      "\n",
      "    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py\", line 1444, in None  *\n",
      "        lambda *inputs : model(inputs)\n",
      "    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "    ValueError: Exception encountered when calling layer 'tf.nn.convolution_610' (type TFOpLambda).\n",
      "    \n",
      "    Number of groups must not be 0 for '{{node model_160/tf.nn.convolution_610/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_160/tf.compat.v1.transpose_306/transpose, model_160/tf.nn.convolution_610/convolution/filter)' with input shapes: [0,82,2,0], [3,3,16,8].\n",
      "    \n",
      "    Call arguments received by layer 'tf.nn.convolution_610' (type TFOpLambda):\n",
      "      â€¢ input=tf.Tensor(shape=(0, 82, 2, 0), dtype=float32)\n",
      "      â€¢ filters=tf.Tensor(shape=(3, 3, 16, 8), dtype=float32)\n",
      "      â€¢ strides=['1', '1']\n",
      "      â€¢ padding='VALID'\n",
      "      â€¢ data_format=None\n",
      "      â€¢ dilations=['1', '1']\n",
      "      â€¢ name=None\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py\", line 1444, in None  *\n        lambda *inputs : model(inputs)\n    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'tf.nn.convolution_610' (type TFOpLambda).\n    \n    Number of groups must not be 0 for '{{node model_160/tf.nn.convolution_610/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_160/tf.compat.v1.transpose_306/transpose, model_160/tf.nn.convolution_610/convolution/filter)' with input shapes: [0,82,2,0], [3,3,16,8].\n    \n    Call arguments received by layer 'tf.nn.convolution_610' (type TFOpLambda):\n      â€¢ input=tf.Tensor(shape=(0, 82, 2, 0), dtype=float32)\n      â€¢ filters=tf.Tensor(shape=(3, 3, 16, 8), dtype=float32)\n      â€¢ strides=['1', '1']\n      â€¢ padding='VALID'\n      â€¢ data_format=None\n      â€¢ dilations=['1', '1']\n      â€¢ name=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m model = YOLO(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mruns/detect/phone_detection2/weights/best.pt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mdetect\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Export with fixed batch size and standard image size\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtflite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Standard YOLO input size (must be divisible by 32)\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Critical: disable dynamic shapes\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Simplify the model graph\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fixed batch size\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:709\u001b[39m, in \u001b[36mModel.export\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    701\u001b[39m custom = {\n\u001b[32m    702\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimgsz\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model.args[\u001b[33m\"\u001b[39m\u001b[33mimgsz\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    703\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    706\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[32m    708\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mexport\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:573\u001b[39m, in \u001b[36mExporter.__call__\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tf_format:  \u001b[38;5;66;03m# TensorFlow formats\u001b[39;00m\n\u001b[32m    572\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.int8 |= edgetpu\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     f[\u001b[32m5\u001b[39m], keras_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n\u001b[32m    575\u001b[39m         f[\u001b[32m6\u001b[39m] = \u001b[38;5;28mself\u001b[39m.export_pb(keras_model=keras_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:249\u001b[39m, in \u001b[36mtry_export.<locals>.outer_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    248\u001b[39m     LOGGER.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m export failure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt.t\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:241\u001b[39m, in \u001b[36mtry_export.<locals>.outer_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         f = \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# exported file/dir or tuple of (file/dir, *)\u001b[39;00m\n\u001b[32m    242\u001b[39m     path = f \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m f[\u001b[32m0\u001b[39m]\n\u001b[32m    243\u001b[39m     mb = file_size(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:1079\u001b[39m, in \u001b[36mExporter.export_saved_model\u001b[39m\u001b[34m(self, prefix)\u001b[39m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28mself\u001b[39m.args.simplify = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1078\u001b[39m f_onnx = \u001b[38;5;28mself\u001b[39m.export_onnx()  \u001b[38;5;66;03m# ensure ONNX is available\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m keras_model = \u001b[43monnx2saved_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mint8\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtfjs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43medgetpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1087\u001b[39m YAML.save(f / \u001b[33m\"\u001b[39m\u001b[33mmetadata.yaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.metadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# Add TFLite metadata\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/utils/export/tensorflow.py:114\u001b[39m, in \u001b[36monnx2saved_model\u001b[39m\u001b[34m(onnx_file, output_dir, int8, images, disable_group_convolution, prefix)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx2tf\u001b[39;00m  \u001b[38;5;66;03m# scoped for after ONNX export for reduced conflict during import\u001b[39;00m\n\u001b[32m    113\u001b[39m LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m keras_model = \u001b[43monnx2tf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43monnx_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# note INT8-FP16 activation bug https://github.com/ultralytics/ultralytics/issues/15873\u001b[39;49;00m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_batchmatmul_unfold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix lower no. of detected objects on GPU delegate\u001b[39;49;00m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_signaturedefs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix error with Attention block group convolution\u001b[39;49;00m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix error with group convolution\u001b[39;49;00m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Remove/rename TFLite models\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m int8:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py:1447\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_norm_mean, quant_norm_std, quant_type, custom_input_op_name_np_data_path, input_quant_dtype, output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, shape_hints, no_large_tensor, output_nms_with_dynamic_tensor, switch_nms_version, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, auto_generate_json, auto_generate_json_on_error, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;66;03m# Create concrete func\u001b[39;00m\n\u001b[32m   1443\u001b[39m run_model = tf.function(\n\u001b[32m   1444\u001b[39m     func=\u001b[38;5;28;01mlambda\u001b[39;00m *inputs : model(inputs),\n\u001b[32m   1445\u001b[39m     input_signature=[tf.TensorSpec(tensor.shape, tensor.dtype, tensor.name) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m model.inputs],\n\u001b[32m   1446\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m concrete_func = \u001b[43mrun_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m SIGNATURE_KEY = \u001b[33m'\u001b[39m\u001b[33mserving_default\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1451\u001b[39m \u001b[38;5;66;03m# saved_model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1256\u001b[39m, in \u001b[36mFunction.get_concrete_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1255\u001b[39m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m   concrete = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m   concrete._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1258\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1226\u001b[39m, in \u001b[36mFunction._get_concrete_function_garbage_collected\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1224\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     initializers = []\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_uninitialized_variables(initializers)\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m   1230\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m   1231\u001b[39m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.ag_error_metadata.to_exception(e)\n\u001b[32m     53\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    438\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     result = \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    441\u001b[39m     result = converted_f(*effective_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/1b/fqvm4rqj4_b4lmmb__m8ls880000gn/T/__autograph_generated_filelwgx5zgr.py:6\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[39m\u001b[34m(*inputs)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner_factory\u001b[39m(ag__):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     tf__lam = \u001b[38;5;28;01mlambda\u001b[39;00m *inputs: \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlscope\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_convert_user_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/function_wrappers.py:113\u001b[39m, in \u001b[36mwith_function_scope\u001b[39m\u001b[34m(thunk, scope_name, options)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[33m'\u001b[39m\u001b[33mlambda_\u001b[39m\u001b[33m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/1b/fqvm4rqj4_b4lmmb__m8ls880000gn/T/__autograph_generated_filelwgx5zgr.py:6\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[39m\u001b[34m(lscope)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner_factory\u001b[39m(ag__):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     tf__lam = \u001b[38;5;28;01mlambda\u001b[39;00m *inputs: ag__.with_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mlscope\u001b[39m\u001b[33m'\u001b[39m, ag__.ConversionOptions(recursive=\u001b[38;5;28;01mTrue\u001b[39;00m, user_requested=\u001b[38;5;28;01mTrue\u001b[39;00m, optional_features=(), internal_convert_user_code=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    374\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options.user_requested \u001b[38;5;129;01mand\u001b[39;00m conversion.is_allowlisted(f):\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options.internal_convert_user_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:1060\u001b[39m, in \u001b[36m_create_c_op\u001b[39m\u001b[34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[39m\n\u001b[32m   1057\u001b[39m   c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.InvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1059\u001b[39m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.message)\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[31mValueError\u001b[39m: in user code:\n\n    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py\", line 1444, in None  *\n        lambda *inputs : model(inputs)\n    File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'tf.nn.convolution_610' (type TFOpLambda).\n    \n    Number of groups must not be 0 for '{{node model_160/tf.nn.convolution_610/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_160/tf.compat.v1.transpose_306/transpose, model_160/tf.nn.convolution_610/convolution/filter)' with input shapes: [0,82,2,0], [3,3,16,8].\n    \n    Call arguments received by layer 'tf.nn.convolution_610' (type TFOpLambda):\n      â€¢ input=tf.Tensor(shape=(0, 82, 2, 0), dtype=float32)\n      â€¢ filters=tf.Tensor(shape=(3, 3, 16, 8), dtype=float32)\n      â€¢ strides=['1', '1']\n      â€¢ padding='VALID'\n      â€¢ data_format=None\n      â€¢ dilations=['1', '1']\n      â€¢ name=None\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\n",
    "    \"runs/detect/phone_detection2/weights/best.pt\",\n",
    "    task=\"detect\",\n",
    ")\n",
    "\n",
    "# Export with fixed batch size and standard image size\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    imgsz=640,  # Standard YOLO input size (must be divisible by 32)\n",
    "    dynamic=False,  # Critical: disable dynamic shapes\n",
    "    simplify=True,  # Simplify the model graph\n",
    "    batch=1,  # Fixed batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19d48a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.248 ðŸš€ Python-3.12.10 torch-2.9.1 CPU (Apple M4 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/phone_detection2/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 300, 6) (5.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxslim>=0.1.71 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (0.1.82)\n",
      "Requirement already satisfied: onnxruntime in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (1.23.2)\n",
      "Requirement already satisfied: colorama in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.6)\n",
      "Requirement already satisfied: ml-dtypes in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.1)\n",
      "Requirement already satisfied: onnx in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.19.0)\n",
      "Requirement already satisfied: packaging in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Requirement already satisfied: sympy>=1.13.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (25.12.19)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (2.0.2)\n",
      "Requirement already satisfied: protobuf in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from sympy>=1.13.1->onnxslim>=0.1.71) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnx->onnxslim>=0.1.71) (4.15.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.6s\n",
      "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: onnxslim>=0.1.71 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (0.1.82)\n",
      "Requirement already satisfied: onnxruntime in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (1.23.2)\n",
      "Requirement already satisfied: colorama in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.6)\n",
      "Requirement already satisfied: ml-dtypes in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (0.4.1)\n",
      "Requirement already satisfied: onnx in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.19.0)\n",
      "Requirement already satisfied: packaging in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Requirement already satisfied: sympy>=1.13.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (25.12.19)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (2.0.2)\n",
      "Requirement already satisfied: protobuf in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from sympy>=1.13.1->onnxslim>=0.1.71) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/vongocsang/Documents/working/Renn/ai_agents/.venv/lib/python3.12/site-packages (from onnx->onnxslim>=0.1.71) (4.15.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.3s\n",
      "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 22...\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.8s, saved as 'runs/detect/phone_detection2/weights/best.onnx' (10.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "\u001b[31mERROR:\u001b[0m The trace log is below.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py\", line 314, in print_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py\", line 388, in inverted_operation_enable_disable_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py\", line 57, in get_replacement_parameter_wrapper_func\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/ops/Expand.py\", line 151, in make_node\n",
      "    val_model = tf_keras.Model(\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py\", line 166, in __init__\n",
      "    self._init_graph_network(inputs, outputs)\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py\", line 207, in _init_graph_network\n",
      "    self._validate_graph_inputs_and_outputs()\n",
      "  File \"/Users/vongocsang/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py\", line 874, in _validate_graph_inputs_and_outputs\n",
      "    raise ValueError(\n",
      "ValueError: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [1500    4]\n",
      "\n",
      "\u001b[31mERROR:\u001b[0m input_onnx_file_path: runs/detect/phone_detection2/weights/best.onnx\n",
      "\u001b[31mERROR:\u001b[0m onnx_op_name: wa/Expand\n",
      "\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n",
      "\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n",
      "\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n",
      "\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n",
      "ERROR âŒ \u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure 3.1s: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [1500    4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [1500    4]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33mruns/detect/phone_detection2/weights/best.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtflite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Smaller size for mobile\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include NMS in the model\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:709\u001b[39m, in \u001b[36mModel.export\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    701\u001b[39m custom = {\n\u001b[32m    702\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimgsz\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model.args[\u001b[33m\"\u001b[39m\u001b[33mimgsz\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    703\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    706\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[32m    708\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mexport\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:573\u001b[39m, in \u001b[36mExporter.__call__\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tf_format:  \u001b[38;5;66;03m# TensorFlow formats\u001b[39;00m\n\u001b[32m    572\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.int8 |= edgetpu\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     f[\u001b[32m5\u001b[39m], keras_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n\u001b[32m    575\u001b[39m         f[\u001b[32m6\u001b[39m] = \u001b[38;5;28mself\u001b[39m.export_pb(keras_model=keras_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:249\u001b[39m, in \u001b[36mtry_export.<locals>.outer_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    248\u001b[39m     LOGGER.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m export failure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt.t\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:241\u001b[39m, in \u001b[36mtry_export.<locals>.outer_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         f = \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# exported file/dir or tuple of (file/dir, *)\u001b[39;00m\n\u001b[32m    242\u001b[39m     path = f \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m f[\u001b[32m0\u001b[39m]\n\u001b[32m    243\u001b[39m     mb = file_size(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/engine/exporter.py:1079\u001b[39m, in \u001b[36mExporter.export_saved_model\u001b[39m\u001b[34m(self, prefix)\u001b[39m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28mself\u001b[39m.args.simplify = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1078\u001b[39m f_onnx = \u001b[38;5;28mself\u001b[39m.export_onnx()  \u001b[38;5;66;03m# ensure ONNX is available\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m keras_model = \u001b[43monnx2saved_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mint8\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtfjs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43medgetpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1087\u001b[39m YAML.save(f / \u001b[33m\"\u001b[39m\u001b[33mmetadata.yaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.metadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# Add TFLite metadata\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/ultralytics/utils/export/tensorflow.py:114\u001b[39m, in \u001b[36monnx2saved_model\u001b[39m\u001b[34m(onnx_file, output_dir, int8, images, disable_group_convolution, prefix)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx2tf\u001b[39;00m  \u001b[38;5;66;03m# scoped for after ONNX export for reduced conflict during import\u001b[39;00m\n\u001b[32m    113\u001b[39m LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m keras_model = \u001b[43monnx2tf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43monnx_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# note INT8-FP16 activation bug https://github.com/ultralytics/ultralytics/issues/15873\u001b[39;49;00m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_batchmatmul_unfold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix lower no. of detected objects on GPU delegate\u001b[39;49;00m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_signaturedefs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix error with Attention block group convolution\u001b[39;49;00m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# fix error with group convolution\u001b[39;49;00m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Remove/rename TFLite models\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m int8:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py:1304\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_norm_mean, quant_norm_std, quant_type, custom_input_op_name_np_data_path, input_quant_dtype, output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, shape_hints, no_large_tensor, output_nms_with_dynamic_tensor, switch_nms_version, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, auto_generate_json, auto_generate_json_on_error, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[39m\n\u001b[32m   1300\u001b[39m             warn(\n\u001b[32m   1301\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mConversion failed and automatic JSON generation could not find a solution after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m attempts.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1302\u001b[39m             )\n\u001b[32m   1303\u001b[39m     \u001b[38;5;66;03m# Re-raise the original error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m additional_parameters[\u001b[33m'\u001b[39m\u001b[33monnx_tensor_infos_for_validation\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m onnx_tensor_infos_for_validation\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/onnx2tf.py:1218\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_norm_mean, quant_norm_std, quant_type, custom_input_op_name_np_data_path, input_quant_dtype, output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, shape_hints, no_large_tensor, output_nms_with_dynamic_tensor, switch_nms_version, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, auto_generate_json, auto_generate_json_on_error, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[39m\n\u001b[32m   1214\u001b[39m \u001b[38;5;66;03m# substitution because saved_model does not allow colons\u001b[39;00m\n\u001b[32m   1215\u001b[39m \u001b[38;5;66;03m# Substitution because saved_model does not allow leading slashes in op names\u001b[39;00m\n\u001b[32m   1216\u001b[39m sanitizing(graph_node)\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtf_layers_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf_layers_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m op_counta += \u001b[32m1\u001b[39m\n\u001b[32m   1224\u001b[39m additional_parameters[\u001b[33m'\u001b[39m\u001b[33mop_counta\u001b[39m\u001b[33m'\u001b[39m] = op_counta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py:314\u001b[39m, in \u001b[36mprint_node_info.<locals>.print_wrapper_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m             debug(\n\u001b[32m    308\u001b[39m                 Color.GREEN(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mINFO:\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m+\n\u001b[32m    309\u001b[39m                 Color.CYAN(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m output_name.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m) + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mre.sub(\u001b[33m\"\u001b[39m\u001b[33m^wa/\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39mgraph_node_output.name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m+\n\u001b[32m    310\u001b[39m                 Color.CYAN(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_node_output.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m+\n\u001b[32m    311\u001b[39m                 Color.CYAN(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_node_output.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    312\u001b[39m             )\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_log_level() <= LOG_LEVELS[\u001b[33m'\u001b[39m\u001b[33mdebug\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m graph_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tf_layers_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py:388\u001b[39m, in \u001b[36minverted_operation_enable_disable.<locals>.inverted_operation_enable_disable_wrapper_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverted_operation_enable_disable_wrapper_func\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    The output_shape_trans stores the result of determining\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    whether the final output shape of the connected OP differs between ONNX and TensorFlow.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m    False: No transposition\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    398\u001b[39m     graph_node = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mgraph_node\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/utils/common_functions.py:57\u001b[39m, in \u001b[36mget_replacement_parameter.<locals>.get_replacement_parameter_wrapper_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m replacement_parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     52\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mop_rep_params\u001b[39m\u001b[33m'\u001b[39m] = [\n\u001b[32m     53\u001b[39m         replacement_parameter \\\n\u001b[32m     54\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m replacement_parameter \u001b[38;5;129;01min\u001b[39;00m replacement_parameters \\\n\u001b[32m     55\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m replacement_parameter[\u001b[33m'\u001b[39m\u001b[33mop_name\u001b[39m\u001b[33m'\u001b[39m] == op_name\n\u001b[32m     56\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/onnx2tf/ops/Expand.py:151\u001b[39m, in \u001b[36mmake_node\u001b[39m\u001b[34m(graph_node, tf_layers_dict, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_tensor_shape, np.ndarray):\n\u001b[32m    150\u001b[39m         expand_shape = [input_tensor_shape]\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     val_model = \u001b[43mtf_keras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf_model_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py:204\u001b[39m, in \u001b[36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m   result = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    206\u001b[39m   \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py:166\u001b[39m, in \u001b[36mFunctional.__init__\u001b[39m\u001b[34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    158\u001b[39m         [\n\u001b[32m    159\u001b[39m             functional_utils.is_input_keras_tensor(t)\n\u001b[32m    160\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf.nest.flatten(inputs)\n\u001b[32m    161\u001b[39m         ]\n\u001b[32m    162\u001b[39m     ):\n\u001b[32m    163\u001b[39m         inputs, outputs = functional_utils.clone_graph_nodes(\n\u001b[32m    164\u001b[39m             inputs, outputs\n\u001b[32m    165\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py:204\u001b[39m, in \u001b[36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m   result = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    206\u001b[39m   \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py:207\u001b[39m, in \u001b[36mFunctional._init_graph_network\u001b[39m\u001b[34m(self, inputs, outputs)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    203\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m\"\u001b[39m\u001b[33m_keras_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outputs\n\u001b[32m    204\u001b[39m     ):\n\u001b[32m    205\u001b[39m         base_layer_utils.create_keras_history(\u001b[38;5;28mself\u001b[39m._nested_outputs)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_graph_inputs_and_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# built.\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/working/Qlay/yolo-training/.venv/lib/python3.12/site-packages/tf_keras/src/engine/functional.py:874\u001b[39m, in \u001b[36mFunctional._validate_graph_inputs_and_outputs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m_keras_history\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    873\u001b[39m     cls_name = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    875\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutput tensors of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model must be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    876\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe output of a TensorFlow `Layer` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    877\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(thus holding past layer metadata). Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    878\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: [1500    4]"
     ]
    }
   ],
   "source": [
    "# Alternative: Try with smaller image size if above fails\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/phone_detection2/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    imgsz=320,  # Smaller size for mobile\n",
    "    dynamic=False,\n",
    "    simplify=True,\n",
    "    batch=1,\n",
    "    nms=True,  # Include NMS in the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c948a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
